{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入相关的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "from neo4j import GraphDatabase  \n",
    "import time  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neo4j配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI=\"bolt://localhost:7687\"  \n",
    "NEO4J_USERNAME=\"neo4j\"  \n",
    "NEO4J_PASSWORD=\"YH1223725\"  \n",
    "NEO4J_DATABASE=\"neo4j\"  \n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个批处理方法， 使用批处理方法将数据导入 Neo4j 。\n",
    "\n",
    "参数：statement 是要执行的 Cypher 查询，df 是要导入的数据框，batch_size 是每批要导入的行数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_import(statement, df, batch_size=1000):  \n",
    "    total = len(df)  \n",
    "    start_s = time.time()  \n",
    "    for start in range(0,total, batch_size):  \n",
    "        batch = df.iloc[start: min(start+batch_size,total)]  \n",
    "        result = driver.execute_query(\"UNWIND $rows AS value \" + statement,  \n",
    "                                      rows=batch.to_dict('records'),  \n",
    "                                      database_=NEO4J_DATABASE)  \n",
    "        print(result.summary.counters)  \n",
    "    print(f'{total} rows in { time.time() - start_s} s.')  \n",
    "    return total  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique\n",
      "  \n",
      "create constraint document_id if not exists for (d:__Document__) require d.id is unique\n",
      "  \n",
      "create constraint entity_id if not exists for (c:__Community__) require c.community is unique\n",
      "  \n",
      "create constraint entity_id if not exists for (e:__Entity__) require e.id is unique\n",
      "  \n",
      "create constraint entity_title if not exists for (e:__Entity__) require e.name is unique\n",
      "  \n",
      "create constraint entity_title if not exists for (e:__Covariate__) require e.title is unique\n",
      "  \n",
      "create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique\n"
     ]
    }
   ],
   "source": [
    "statements = \"\"\"  \n",
    "create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique;  \n",
    "create constraint document_id if not exists for (d:__Document__) require d.id is unique;  \n",
    "create constraint entity_id if not exists for (c:__Community__) require c.community is unique;  \n",
    "create constraint entity_id if not exists for (e:__Entity__) require e.id is unique;  \n",
    "create constraint entity_title if not exists for (e:__Entity__) require e.name is unique;  \n",
    "create constraint entity_title if not exists for (e:__Covariate__) require e.title is unique;  \n",
    "create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique;  \n",
    "\"\"\".split(\";\")  \n",
    "for statement in statements:  \n",
    "    if len((statement or \"\").strip()) > 0:  \n",
    "        print(statement)  \n",
    "        driver.execute_query(statement) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 id          title\n",
      "0  8009aa9fb1bd7977f381d7f84afebb2e  emergency.txt\n",
      "1  617ce69cd329921fdad91acf862e69dd      flood.txt\n"
     ]
    }
   ],
   "source": [
    "doc_df = pd.read_parquet(f'D:/GISERR/graduate_study/pytorch/graphrag/ragtest/output/create_final_documents.parquet', columns=[\"id\", \"title\"])  \n",
    "print(doc_df.head(2)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'labels_added': 3, 'nodes_created': 3, 'properties_set': 6}\n",
      "3 rows in 0.17892837524414062 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement = \"\"\"  \n",
    "MERGE (d:__Document__ {id:value.id})  \n",
    "SET d += value {.title}\n",
    "\"\"\"  \n",
    "batched_import(statement, doc_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>document_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>990e23eb0b27c888fce4fa446cfdc2c8</td>\n",
       "      <td>城市暴雨内涝综述：特征、机理、数据与方法\\n黄华兵1,2,3\\n，王先伟1,2,3\\n，柳 ...</td>\n",
       "      <td>1200</td>\n",
       "      <td>[137a8b999a70d2d8969368ee2ab87297]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f18f9f23d9fd658e9ce600c56035755d</td>\n",
       "      <td>2 年 184 个，2013 年 234 个，而且在大江\\n大河水势基本调控平稳的情况下 2...</td>\n",
       "      <td>1200</td>\n",
       "      <td>[137a8b999a70d2d8969368ee2ab87297]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  990e23eb0b27c888fce4fa446cfdc2c8   \n",
       "1  f18f9f23d9fd658e9ce600c56035755d   \n",
       "\n",
       "                                                text  n_tokens  \\\n",
       "0  城市暴雨内涝综述：特征、机理、数据与方法\\n黄华兵1,2,3\\n，王先伟1,2,3\\n，柳 ...      1200   \n",
       "1  2 年 184 个，2013 年 234 个，而且在大江\\n大河水势基本调控平稳的情况下 2...      1200   \n",
       "\n",
       "                         document_ids  \n",
       "0  [137a8b999a70d2d8969368ee2ab87297]  \n",
       "1  [137a8b999a70d2d8969368ee2ab87297]  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = pd.read_parquet(f'D:/GISERR/graduate_study/pytorch/graphrag/ragtest/output/create_final_text_units.parquet',  \n",
    "                          columns=[\"id\",\"text\",\"n_tokens\",\"document_ids\"])  \n",
    "text_df.head(2)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'labels_added': 61, 'relationships_created': 61, 'nodes_created': 61, 'properties_set': 183}\n",
      "61 rows in 0.3596787452697754 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement = \"\"\"  \n",
    "MERGE (c:__Chunk__ {id:value.id})  \n",
    "SET c += value {.text, .n_tokens}  \n",
    "WITH c, value  \n",
    "UNWIND value.document_ids AS document  \n",
    "MATCH (d:__Document__ {id:document})  \n",
    "MERGE (c)-[:PART_OF]->(d)  \n",
    "\"\"\"  \n",
    "batched_import(statement, text_df)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>id</th>\n",
       "      <th>text_unit_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>黄华兵</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>Huang Huabing is the first author of the artic...</td>\n",
       "      <td>0</td>\n",
       "      <td>d94a9924432343c782cb3e85a8dd6403</td>\n",
       "      <td>[8cd8d68773216fe3d60265af9b8405b9, 990e23eb0b2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>王先伟</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>Wang Xianwei is a co-author of the article tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>fd82935686be4562ad30241efbbd3c48</td>\n",
       "      <td>[990e23eb0b27c888fce4fa446cfdc2c8, f18f9f23d9f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name    type                                        description  \\\n",
       "0  黄华兵  PERSON  Huang Huabing is the first author of the artic...   \n",
       "1  王先伟  PERSON  Wang Xianwei is a co-author of the article tha...   \n",
       "\n",
       "   human_readable_id                                id  \\\n",
       "0                  0  d94a9924432343c782cb3e85a8dd6403   \n",
       "1                  1  fd82935686be4562ad30241efbbd3c48   \n",
       "\n",
       "                                       text_unit_ids  \n",
       "0  [8cd8d68773216fe3d60265af9b8405b9, 990e23eb0b2...  \n",
       "1  [990e23eb0b27c888fce4fa446cfdc2c8, f18f9f23d9f...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_df = pd.read_parquet(f'D:/GISERR/graduate_study/pytorch/graphrag/ragtest/output/create_final_entities.parquet',  \n",
    "                            columns=[\"name\",\"type\",\"description\",\"human_readable_id\",\"id\",\"text_unit_ids\"])  \n",
    "entity_df.head(2)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'labels_added': 558, 'relationships_created': 699, 'nodes_created': 558, 'properties_set': 2232}\n",
      "558 rows in 1.1159262657165527 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "558"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_statement = \"\"\"  \n",
    "MERGE (e:__Entity__ {id:value.id})  \n",
    "SET e += value {.human_readable_id, .description, name:replace(value.name,'\"','')}  \n",
    "WITH e, value  \n",
    "  \n",
    "UNWIND value.text_unit_ids AS text_unit  \n",
    "MATCH (c:__Chunk__ {id:text_unit})  \n",
    "MERGE (c)-[:HAS_ENTITY]->(e)  \n",
    "\"\"\"  \n",
    "batched_import(entity_statement, entity_df)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>weight</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>description</th>\n",
       "      <th>text_unit_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>黄华兵</td>\n",
       "      <td>中山大学地理科学与规划学院</td>\n",
       "      <td>45ac7a6a1d9a449d8b1f019d2ad20121</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>黄华兵在中山大学地理科学与规划学院工作</td>\n",
       "      <td>[990e23eb0b27c888fce4fa446cfdc2c8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>黄华兵</td>\n",
       "      <td>广东省公共安全与灾害工程技术研究中心</td>\n",
       "      <td>584ab7150fb74552a40a266d51645ffa</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>黄华兵在广东省公共安全与灾害工程技术研究中心工作</td>\n",
       "      <td>[990e23eb0b27c888fce4fa446cfdc2c8]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source              target                                id  rank  weight  \\\n",
       "0    黄华兵       中山大学地理科学与规划学院  45ac7a6a1d9a449d8b1f019d2ad20121    10     8.0   \n",
       "1    黄华兵  广东省公共安全与灾害工程技术研究中心  584ab7150fb74552a40a266d51645ffa     9     8.0   \n",
       "\n",
       "  human_readable_id               description  \\\n",
       "0                 0       黄华兵在中山大学地理科学与规划学院工作   \n",
       "1                 1  黄华兵在广东省公共安全与灾害工程技术研究中心工作   \n",
       "\n",
       "                        text_unit_ids  \n",
       "0  [990e23eb0b27c888fce4fa446cfdc2c8]  \n",
       "1  [990e23eb0b27c888fce4fa446cfdc2c8]  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_df = pd.read_parquet(f'D:/GISERR/graduate_study/pytorch/graphrag/ragtest/output/create_final_relationships.parquet',  \n",
    "                         columns=[\"source\",\"target\",\"id\",\"rank\",\"weight\",\"human_readable_id\",\"description\",\"text_unit_ids\"])  \n",
    "rel_df.head(2)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'relationships_created': 517, 'properties_set': 3102}\n",
      "517 rows in 0.5728490352630615 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_statement = \"\"\"  \n",
    "    MATCH (source:__Entity__ {name:replace(value.source,'\"','')})  \n",
    "    MATCH (target:__Entity__ {name:replace(value.target,'\"','')})  \n",
    "    // not necessary to merge on id as there is only one relationship per pair  \n",
    "    MERGE (source)-[rel:RELATED {id: value.id}]->(target)  \n",
    "    SET rel += value {.rank, .weight, .human_readable_id, .description, .text_unit_ids}  \n",
    "    RETURN count(*) as createdRels  \n",
    "\"\"\"  \n",
    "batched_import(rel_statement, rel_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>level</th>\n",
       "      <th>title</th>\n",
       "      <th>text_unit_ids</th>\n",
       "      <th>relationship_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Community 10</td>\n",
       "      <td>[1741a115769bf8f5939be7ddabffd710, 1149517f738...</td>\n",
       "      <td>[8d3bbdef620148619d2496175f3c290a, 3e3478a4526...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Community 5</td>\n",
       "      <td>[7d88ce694c885e6ebcfc2aa4797648ad, 7d88ce694c8...</td>\n",
       "      <td>[0280c199824b45bb9e0a1fcf88fde693, 379fb0ac9fb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  level         title                                      text_unit_ids  \\\n",
       "0  10      0  Community 10  [1741a115769bf8f5939be7ddabffd710, 1149517f738...   \n",
       "1   5      0   Community 5  [7d88ce694c885e6ebcfc2aa4797648ad, 7d88ce694c8...   \n",
       "\n",
       "                                    relationship_ids  \n",
       "0  [8d3bbdef620148619d2496175f3c290a, 3e3478a4526...  \n",
       "1  [0280c199824b45bb9e0a1fcf88fde693, 379fb0ac9fb...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community_df = pd.read_parquet(f'D:/GISERR/graduate_study/pytorch/graphrag/ragtest/output/create_final_communities.parquet',  \n",
    "                     columns=[\"id\",\"level\",\"title\",\"text_unit_ids\",\"relationship_ids\"])  \n",
    "community_df.head(2)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'labels_added': 41, 'relationships_created': 462, 'nodes_created': 41, 'properties_set': 123}\n",
      "41 rows in 1.1223158836364746 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement = \"\"\"  \n",
    "MERGE (c:__Community__ {community:value.id})  \n",
    "SET c += value {.level, .title}  \n",
    "/*  \n",
    "UNWIND value.text_unit_ids as text_unit_id  \n",
    "MATCH (t:__Chunk__ {id:text_unit_id})  \n",
    "MERGE (c)-[:HAS_CHUNK]->(t)  \n",
    "WITH distinct c, value  \n",
    "*/  \n",
    "WITH *  \n",
    "UNWIND value.relationship_ids as rel_id  \n",
    "MATCH (start:__Entity__)-[:RELATED {id:rel_id}]->(end:__Entity__)  \n",
    "MERGE (start)-[:IN_COMMUNITY]->(c)  \n",
    "MERGE (end)-[:IN_COMMUNITY]->(c)  \n",
    "RETURN count(distinct c) as createdCommunities  \n",
    "\"\"\"  \n",
    "batched_import(statement, community_df)  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
